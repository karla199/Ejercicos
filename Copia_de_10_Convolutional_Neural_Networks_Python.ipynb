{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "colab": {
      "name": "Copia de 10. Convolutional Neural Networks - Python.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karla199/PracticasAzure/blob/main/Copia_de_10_Convolutional_Neural_Networks_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bra0spBj-zg8"
      },
      "source": [
        "Convolutional Neural Networks\n",
        "======\n",
        "\n",
        "Convolutional neural networks (CNNs) are a class of deep neural networks, most commonly used in computer vision applications.\n",
        "\n",
        "Convolutional refers the network pre-processing data for you - traditionally this pre-processing was performed by data scientists. The neural network can learn how to do pre-processing *itself* by applying filters for things such as edge detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rMxa0lR-7O7",
        "outputId": "ee439f86-79d8-40c3-99e3-778b1bab993b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnmjxuKg-zhG"
      },
      "source": [
        "Step 1\n",
        "-----\n",
        "\n",
        "In this exercise we will train a CNN to recognise handwritten digits, using the MNIST digit dataset.\n",
        "\n",
        "This is a very common exercise and data set to learn from.\n",
        "\n",
        "Let's start by loading our dataset and setting up our train, validation, and test sets.\n",
        "\n",
        "#### Run the code below to import our required libraries and set up the graphing features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DNplrgmW-zhM",
        "outputId": "7d415e36-762a-48b5-c449-718f50a466a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Run this!\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "print('keras using %s backend'%keras.backend.backend())\n",
        "import matplotlib.pyplot as graph\n",
        "%matplotlib inline\n",
        "graph.rcParams['figure.figsize'] = (15,5)\n",
        "graph.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
        "graph.rcParams[\"font.size\"] = '12'\n",
        "graph.rcParams['image.cmap'] = 'rainbow'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras using tensorflow backend\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2dli6hH-zhl"
      },
      "source": [
        "### In the cell below replace:\n",
        "#### 1. `<addTrainX>` with `train_X`\n",
        "#### 2. `<addTrainY>` with `train_Y`\n",
        "#### 3. `<addValidX>` with `valid_X`\n",
        "#### 4. `<addValidY>` with `valid_Y`\n",
        "#### 5. `<addTextX>` with `test_X`\n",
        "#### 6. `<addTextY>` with `test_Y`\n",
        "#### and then __run the code__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "luT_mzFH-zho",
        "outputId": "c6f9508f-9967-4415-bd8c-233b2729e5f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Here we import the dataset, and split it into the training, validation, and test sets.\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# This is our training data, with 6400 samples.\n",
        "###\n",
        "# REPLACE <addTrainX> WITH train_X AND <addTrainY> WITH train_Y\n",
        "###\n",
        "train_X = mnist.load_data()[0][0][:6400].astype('float32')\n",
        "train_Y = mnist.load_data()[0][1][:6400]\n",
        "###\n",
        "\n",
        "# This is our validation data, with 1600 samples.\n",
        "###\n",
        "# REPLACE <addValidX> WITH valid_X AND <addValidY> WITH valid_Y\n",
        "###\n",
        "valid_X = mnist.load_data()[1][0][:1600].astype('float32')\n",
        "valid_Y = mnist.load_data()[1][1][:1600]\n",
        "###\n",
        "\n",
        "# This is our test data, with 2000 samples.\n",
        "###\n",
        "# REPLACE <addTextX> WITH test_X AND <addTextY> WITH test_Y\n",
        "###\n",
        "test_X = mnist.load_data()[1][0][-2000:].astype('float32')\n",
        "test_Y = mnist.load_data()[1][1][-2000:]\n",
        "###\n",
        "\n",
        "print('train_X:', train_X.shape, end = '')\n",
        "print(', train_Y:', train_Y.shape)\n",
        "print('valid_X:', valid_X.shape, end = '')\n",
        "print(', valid_Y:', valid_Y.shape)\n",
        "print('test_X:', test_X.shape, end = '')\n",
        "print(', test_Y:', test_Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "train_X: (6400, 28, 28), train_Y: (6400,)\n",
            "valid_X: (1600, 28, 28), valid_Y: (1600,)\n",
            "test_X: (2000, 28, 28), test_Y: (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYALPhJ1-zh3"
      },
      "source": [
        "So we have 6400 training samples, 1600 validation samples, and 2000 test samples.\n",
        "\n",
        "Each sample is an greyscale image - 28 pixels wide and 28 pixels high. Each pixel is really a number from 0 to 255 - 0 being fully black, 255 being fully white. When we graph the 28x28 numbers, we can see the image.\n",
        "\n",
        "Let's have a look at one of our samples.\n",
        "\n",
        "#### Replace `<addSample>` with `train_X[0]` (you can change 0 to any number between 0 and 6400 if you like)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sVHEHSAz-zh5",
        "outputId": "15bb1adf-5422-4453-8ecd-9874e1ed01ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "###\n",
        "# REPLACE THE <addSample> BELOW WITH train_X[0] OR ANOTHER SAMPLE e.g. train_X[1] or train_X[2]\n",
        "###\n",
        "graph.imshow(train_X[0], cmap = 'gray', interpolation = 'nearest')\n",
        "###\n",
        "\n",
        "graph.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUnb9iPn-ziK"
      },
      "source": [
        "Step 2\n",
        "---\n",
        "\n",
        "The neural network will use the 28x28 values of each image to predict what each image represents.\n",
        "\n",
        "As each value is between 0 and 255, we'll scale the values down by dividing by 255 (this makes it faster for the Neural Network to train).\n",
        "\n",
        "We need to reshape our data to get it working well with our neural network. \n",
        "\n",
        "### In the cell below replace:\n",
        "#### 1. `<addRehape>` with `reshape`\n",
        "#### 2. `<completeCalculation>` with `/255`\n",
        "#### and then __run the code__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SK8Oh-MG-ziM",
        "outputId": "3b033ca5-1f41-4e2b-a910-fc33192de67b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# First off, let's reshape our X sets so that they fit the convolutional layers.\n",
        "\n",
        "# This gets the image dimensions - 28\n",
        "dim = train_X[0].shape[0]\n",
        "\n",
        "###\n",
        "# REPLACE THE <addRehape> BELOW WITH reshape\n",
        "###\n",
        "train_X = train_X.reshape(train_X.shape[0], dim, dim, 1)\n",
        "valid_X = valid_X.reshape(valid_X.shape[0], dim, dim, 1)\n",
        "test_X = test_X.reshape(test_X.shape[0], dim, dim, 1)\n",
        "###\n",
        "\n",
        "# Next up - feature scaling.\n",
        "# We scale the values so they are between 0 and 1, instead of 0 and 255.\n",
        "\n",
        "###\n",
        "# REPLACE THE <completeCalculation> BELOW WITH /255\n",
        "###\n",
        "train_X = train_X /255\n",
        "valid_X = valid_X /255\n",
        "test_X = test_X /255\n",
        "###\n",
        "\n",
        "\n",
        "# Now we print the label for the first example\n",
        "print(train_Y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzCAdxGH-ziu"
      },
      "source": [
        "Expected output:  \n",
        "`5`\n",
        "\n",
        "The label is a number - the number we see when we view the image.\n",
        "\n",
        "We need represent this number as a one-hot vector, so the neural network knows it is a category.\n",
        "\n",
        "Keras can convert these labels into one-hot vectors easily with the function - `to_categorical`\n",
        "\n",
        "#### Replace `<addCategorical>` with `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8JE-cLYj-zix",
        "outputId": "dc54b201-d534-4bfc-80e2-6481ad3dbab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###\n",
        "# REPLACE THE <addCategorical> BELOW WITH to_categorical\n",
        "###\n",
        "train_Y = keras.utils.to_categorical(train_Y, 10)\n",
        "valid_Y = keras.utils.to_categorical(valid_Y, 10)\n",
        "test_Y = keras.utils.to_categorical(test_Y, 10)\n",
        "###\n",
        "\n",
        "# 10 being the number of categories (numbers 0 to 9)\n",
        "\n",
        "print(train_Y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoHPzqO--zjD"
      },
      "source": [
        "Expected output:  \n",
        "`[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]`\n",
        "\n",
        "Step 3\n",
        "-----\n",
        "\n",
        "All ready! Time to build another neural network.\n",
        "\n",
        "#### Replace `<addSequential>` with `Sequential()` and run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CpMGR4eX-zjL"
      },
      "source": [
        "# Sets a randomisation seed for replicatability.\n",
        "np.random.seed(6)\n",
        "\n",
        "###\n",
        "# REPLACE THE <addSequential> BELOW WITH Sequential() (don't forget the () )\n",
        "###\n",
        "model = Sequential()\n",
        "###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weZxEwxw-zjr"
      },
      "source": [
        "The __Convolutional__ in Convolutional Neural Networks refers the pre-processing the network can do itself.\n",
        "\n",
        "#### Replace `<addConv2d>` with `Conv2D`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VFFEj1J4-zjv"
      },
      "source": [
        "###\n",
        "# REPLACE THE <addConv2D> BELOW WITH Conv2D\n",
        "###\n",
        "model.add(Conv2D(28, kernel_size = (3, 3), activation = 'relu', input_shape = (dim, dim, 1)))\n",
        "model.add(Conv2D(56, (3, 3), activation = 'relu'))\n",
        "###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc7s6Vit-zkS"
      },
      "source": [
        "Next up we'll:\n",
        "* Add pooling layers.\n",
        "* Apply dropout.\n",
        "* Flatten the data to a vector (the output of step 2 is a vector).\n",
        "\n",
        "### In the cell below replace:\n",
        "#### 1. `<addMaxPooling2D>` with `MaxPooling2D`\n",
        "#### 2. `<addDropout>` with `Dropout`\n",
        "#### 3. `<addFlatten>` with `Flatten()`\n",
        "\n",
        "#### and then __run the code__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ByJ_P38D-zkc",
        "outputId": "b79caec1-1ffb-4d95-8a9e-d9b57e90c967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Pooling layers help speed up training time and make features it detects more robust.\n",
        "# They act by downsampling the data - reducing the data size and complexity.\n",
        "\n",
        "###\n",
        "# REPLACE THE <addMaxPooling2D> BELOW WITH MaxPooling2D\n",
        "###\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "###\n",
        "\n",
        "# Dropout is a technique to help prevent overfitting\n",
        "# It makes nodes 'dropout' - turning them off randomly.\n",
        "\n",
        "###\n",
        "# REPLACE THE <addDropout> BELOW WITH Dropout\n",
        "###\n",
        "model.add(Dropout(0.125))\n",
        "###\n",
        "\n",
        "\n",
        "###\n",
        "# REPLACE THE <addFlatten> BELOW WITH Flatten()\n",
        "###\n",
        "model.add(Flatten())\n",
        "###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8076819144f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# REPLACE THE <addMaxPooling2D> BELOW WITH MaxPooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    219\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1090\u001b[0m       \u001b[0;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    178\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer max_pooling2d_1 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 8064]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Iojcb3i-zkv"
      },
      "source": [
        "#### Replace `<updateHere>` with 10 and run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r8uH-sWh-zk1"
      },
      "source": [
        "# Dense layers perform classification - we have extracted the features with the convolutional pre-processing\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# More dropout!\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Next is our output layer\n",
        "# Softmax outputs the probability for each category\n",
        "###\n",
        "# REPLACE <updateHere> BELOW WITH 10, THE NUMBER OF CLASSES (DIGITS 0 TO 9)\n",
        "###\n",
        "model.add(Dense(10, activation=tf.nn.softmax))\n",
        "###\n",
        "\n",
        "# And finally, we compile.\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCmUorn9-zlP"
      },
      "source": [
        "Step 4\n",
        "-----\n",
        "\n",
        "Let's train it!\n",
        "\n",
        "### In the cell below replace:\n",
        "#### 1. `<addTrainX>` with `train_X `\n",
        "#### 2. `<addTrainY>` with `train_Y`\n",
        "#### 3. `<addValidX>` with `valid_X`\n",
        "#### 4. `<addValidY>` with `valid_Y`\n",
        "#### 5. `<addEvaluate>` with `evaluate`\n",
        "\n",
        "#### and then __run the code__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Gxft5fjn-zlT",
        "outputId": "e851f10a-632c-48ae-8602-cff4cf43127f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        }
      },
      "source": [
        "###\n",
        "# REPLACE THE <addTrainX> WITH train_X, <addTrainY> WITH train_Y, <addValidX> WITH valid_X, AND <addValidY> WITH valid_Y\n",
        "###\n",
        "training_stats = model.fit(train_X, train_Y, batch_size = 128, epochs = 12, verbose = 1, validation_data = (valid_X, valid_Y))\n",
        "###\n",
        "\n",
        "###\n",
        "# REPLACE THE <addEvaluate> BELOW WITH evaluate\n",
        "###\n",
        "evaluation = model.evaluate(test_X, test_Y, verbose=0)\n",
        "###\n",
        "\n",
        "print('Test Set Evaluation: loss = %0.6f, accuracy = %0.2f' %(evaluation[0], 100 * evaluation[1]))\n",
        "\n",
        "# We can plot our training statistics to see how it developed over time\n",
        "accuracy, = graph.plot(training_stats.history['acc'], label = 'Accuracy')\n",
        "training_loss, = graph.plot(training_stats.history['loss'], label = 'Training Loss')\n",
        "graph.legend(handles = [accuracy, training_loss])\n",
        "loss = np.array(training_stats.history['loss'])\n",
        "xp = np.linspace(0,loss.shape[0],10 * loss.shape[0])\n",
        "graph.plot(xp, np.full(xp.shape, 1), c = 'k', linestyle = ':', alpha = 0.5)\n",
        "graph.plot(xp, np.full(xp.shape, 0), c = 'k', linestyle = ':', alpha = 0.5)\n",
        "graph.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "50/50 [==============================] - 14s 277ms/step - loss: 0.8130 - accuracy: 0.7605 - val_loss: 0.4328 - val_accuracy: 0.8681\n",
            "Epoch 2/12\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.3298 - accuracy: 0.9070 - val_loss: 0.3096 - val_accuracy: 0.9044\n",
            "Epoch 3/12\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.2337 - accuracy: 0.9314 - val_loss: 0.2439 - val_accuracy: 0.9250\n",
            "Epoch 4/12\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.1793 - accuracy: 0.9505 - val_loss: 0.1938 - val_accuracy: 0.9400\n",
            "Epoch 5/12\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.1413 - accuracy: 0.9589 - val_loss: 0.1749 - val_accuracy: 0.9481\n",
            "Epoch 6/12\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.1172 - accuracy: 0.9670 - val_loss: 0.1567 - val_accuracy: 0.9531\n",
            "Epoch 7/12\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.1008 - accuracy: 0.9709 - val_loss: 0.1560 - val_accuracy: 0.9563\n",
            "Epoch 8/12\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.0798 - accuracy: 0.9770 - val_loss: 0.1293 - val_accuracy: 0.9613\n",
            "Epoch 9/12\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.0718 - accuracy: 0.9781 - val_loss: 0.1247 - val_accuracy: 0.9638\n",
            "Epoch 10/12\n",
            "50/50 [==============================] - 14s 275ms/step - loss: 0.0610 - accuracy: 0.9828 - val_loss: 0.1238 - val_accuracy: 0.9638\n",
            "Epoch 11/12\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.0560 - accuracy: 0.9848 - val_loss: 0.1209 - val_accuracy: 0.9619\n",
            "Epoch 12/12\n",
            "50/50 [==============================] - 14s 274ms/step - loss: 0.0470 - accuracy: 0.9869 - val_loss: 0.1123 - val_accuracy: 0.9625\n",
            "Test Set Evaluation: loss = 0.061114, accuracy = 98.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ad40aba96444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# We can plot our training statistics to see how it developed over time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf4y442d-zmI"
      },
      "source": [
        "## Step 5\n",
        "\n",
        "Let's test it on a new sample that it hasn't seen, and see how it classifies it!\n",
        "\n",
        "#### Replace `<addNumber>` with any number between 0 and 1999, then run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ErWPbEhZ-zmY"
      },
      "source": [
        "###\n",
        "# REPLACE THE <addNumber> WITH ANY NUMBER BETWEEN 0 AND 1999\n",
        "###\n",
        "sample = test_X[1995].reshape(dim, dim)\n",
        "###\n",
        "\n",
        "graph.imshow(sample, cmap = 'gray', interpolation = 'nearest')\n",
        "graph.show()\n",
        "\n",
        "prediction = model.predict(sample.reshape(1, dim, dim, 1))\n",
        "print('prediction: %i' %(np.argmax(prediction)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISCTGH4R-zmo"
      },
      "source": [
        "How is the prediction? Does it look right?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4kPeU0i-zmt"
      },
      "source": [
        "Conclusion\n",
        "------\n",
        "\n",
        "Congratulations! We've built a convolutional neural network that is able to recognise handwritten digits with very high accuracy.\n",
        "\n",
        "CNN's are very complex - you're not expected to understand everything (or most things) we covered here. They take a lot of time and practise to properly understand each aspect of them.\n",
        "\n",
        "Here we used:  \n",
        "* __Feature scaling__ - reducing the range of the values. This helps improve training time.\n",
        "* __Convolutional layers__ - network layers that pre-process the data for us. These apply filters to extract features for the neural network to analyze.\n",
        "* __Pooling layers__ - part of the Convolutional layers. They apply filters downsample the data - extracting features.\n",
        "* __Dropout__ - a regularization technique to help prevent overfitting.\n",
        "* __Dense layers__ - neural network layers which perform classification on the features extracted by the convolutional layers and downsampled by the pooling layers.\n",
        "* __Softmax__ - an activation function which outputs the probability for each category."
      ]
    }
  ]
}